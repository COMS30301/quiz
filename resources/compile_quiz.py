#!/usr/bin/env python

import re
import sys, os
import json
import argparse
from html_templates import questionCategories,questionTemplate,quizTemplate
from html_templates import singleTemplate
from html_templates import sortTemplate
from html_templates import matrixSort_answers_single,matrixSort_question_single,matrixSort_questionTemplate
from html_templates import tableTemplate
from html_templates import blankItem,blankTemplate
from html_templates import multipleTemplate
from html_templates import iframeGeneralTemplate, iframeIframeTemplate

# command line arguments parser
parser = argparse.ArgumentParser(description='Simple quiz generator.')
parser_group1 = parser.add_mutually_exclusive_group()
parser_group1.add_argument('-q', '--question', type=int, nargs=1, required=False, dest="question", default=None, help=('the # of question to be generated (all questions are generated by default)'))
parser_group1.add_argument('-a', '--all', required=False, dest="all", default=True, action='store_true', help=('generate all of the questions'))
parser_group1.add_argument('-s', '--separate', required=False, dest="separate", default=False, action='store_true', help=('generate all of the questions in separate files'))
parser_group1.add_argument('-i', '--iframe', required=False, dest="iframe", default=False, action='store_true', help=('generate all of the question on one page (iframe)'))

parser_group2 = parser.add_mutually_exclusive_group()
parser_group2.add_argument('-o', '--order', required=False, dest="order", default=False, action='store_true', help=('order the questions first on book section then on difficulty'))
parser_group2.add_argument('-O', '--Order', required=False, dest="Order", default=False, action='store_true', help=('order the questions first on difficulty then on book section'))

parser.add_argument('-d', '--debug', required=False, dest="debug", default=False, action='store_true', help=('indicate the correct answer in the question'))
parser.add_argument('-f', '--feedback', required=False, dest="feedback", default=False, action='store_true', help=('generate feedback for all questions'))
parser.add_argument('-e', '--extract', required=False, dest="extract", default=False, action='store_true', help=('export marked questions to separate file'))
parser.add_argument('-c', '--count', required=False, dest="count", default=False, action='store_true', help=('show difficulty statistics of the quiz file'))
parser.add_argument('filename', type=str, nargs=1, help='path to your `.quiz` file')

#
# find all questions and metadata
#
q_rx = re.compile(r"""
  (?P<fullq>
  # number of the question
  \s*\#\s*(?P<number>\d+)\s*
    (?P<quality>-|~)?\s*
  # Extra text to include in response
  ((feedback)\s*:\s*(?P<text>.+))?\s*
  # question difficulty
  (difficulty)\s*:\s*(?P<difficulty>(easy)|(medium)|(hard))\s*
  # question reference
  (reference)\s*:\s*(?P<chapter>\d+)\.(?P<section>\d+)\s*
  # Question being asked
  (question)\s*:\s*(?P<prompt>.+)\s*
  # image(s) to include in response
  (?P<images>(\s*(image)\s*:.*:\s*(\n|\r\n)\s*.*\s*(\n|\r\n))*)
  # Possible answers to the question
  (answers)\s*:\s*(?P<answer_type>(single)|(multiple)|(sort)|(blank_answer)|(cloze_answer)|(matrix_sort_answer))\s*:
  (?P<answers>(?:\s*(\-|\*|(\d+\s*\)))\s*.+)*  | (?:\s*\d+\s*\|\s*\d+\s*\|\s*\d+\s*(\n|\r\n)-+(\n|\r\n)\s*\d+\s*\|\s*\d+\s*\|\s*\d+\s*(\n|\r\n)-+(\n|\r\n)\s*\d+\s*\|\s*\d+\s*\|\s*\d+\s*)  )\s*
  \s*(?P=number)\s*\#\s*
  )
""", re.X | re.M)
# matrix matcher

#
# UID matcher
#
#
uid_rx = re.compile(r"""
  (.*(?:(?:[a-z]{2}[0-9]{4,5})|(?:[a-z]{5,6})).*(?:(?:[a-z]{2}[0-9]{4,5})|(?:[a-z]{5,6})).*)
""", re.M | re.X)

#
# image regex
#
#
img_rx = re.compile(r"""
  \s*(image)\s*:\s*(?P<caption>.*)\s*:\s*(?P<path>.+)\s*
""", re.X | re.M)

#
# fill in blanks regex
#
blanks_rx = re.compile(r"""
  (?P<text>[^\[\]]+)?
  (\[(?P<blank>[^\]]+)\])?
""", re.X | re.M)

#
# question answer regex
#
answ_rx = re.compile(r"""
  # indicator if correct or not
  #
  # (-) : incorrect
  # (*) : correct
  #
  # or ordering of the answers
  # eg. 1) 2) 3)
  #
# \s*(?P<correct>[-*])
  \s*(?P<correct>\-|\*|(\d+\s*\)))
  # actual text of answer
  \s*(?P<answer>.+)(\n|\r\n)
""", re.X | re.M)

#
# answer contingency table regex
#
mx_rx = re.compile(r"""
  # parse matrix in form of
  #
  # 00 | 01 | 02
  # ------------
  # 10 | 11 | 12
  # ------------
  # 20 | 21 | 22
  #
  \s*(?P<oo>\d+)\s*\|\s*(?P<oi>\d+)\s*\|\s*(?P<oz>\d+)\s*(\n|\r\n)
  -+(\n|\r\n)
  \s*(?P<io>\d+)\s*\|\s*(?P<ii>\d+)\s*\|\s*(?P<iz>\d+)\s*(\n|\r\n)
  -+(\n|\r\n)
  \s*(?P<zo>\d+)\s*\|\s*(?P<zi>\d+)\s*\|\s*(?P<zz>\d+)\s*
""", re.X | re.M)

# debug answers
ANSWERS_DEBUG = False

#
# correct answer indicator
#
def markAnswerCh(answerText):
  return "&laquo;" + " " + answerText
def markAnswerOr(answerText, order):
  return str(order) + "" + "&laquo;" + " " + answerText
def markBlank(answerText):
  return "&raquo;" + answerText + "&laquo;" + " "

#
# blanks converter
#
def mergeBlanks(textList, answers):
  answer = ""
  for i in textList:
    if type(i) == int:
      answer += "[answer]" + answers[i] + "[/answer]"
    elif type(i) == str:
      answer += i
    else:
      print( "Unknown prompt type!" )
      sys.exit(1)
  return answer
def fillBlanks(textList, dictionaryAnswers):
  qs = ""
  for i in textList:
    if type(i) == int:
      qs += ( blankItem % dictionaryAnswers[i] )
    elif type(i) == str:
      qs += i
    else:
      print( "Unknown prompt type!" )
      sys.exit(1)
  return qs

def parseQuestions(filename):
  with open(filename, 'r') as quiz_file:
    quiz_text = quiz_file.read()

  # find the parent url before comments are removed
  url = re.search(r'^url:(.+)', quiz_text, re.M)
  if url:
    url = url.group(1).strip()

  # find title for quiz
  title = re.search(r'^title:(.+)', quiz_text, re.M)
  if title:
    title = title.group(1).strip()

  # find user id
  uid = re.search(r'^uid:(.+)', quiz_text, re.M)
  if uid:
    uid = uid.group(1).strip()

  # remove comments from quiz file
  quiz_text = re.sub(r'//(.+)', "", quiz_text)

  # find all questions
  questions = [m.groupdict() for m in q_rx.finditer(quiz_text)]

  results = []
  question_indeces = []

  difficulty_count = [0, 0, 0]
  used_sections = []
  unique_sections = 0

  for q in questions:

    out = {}

    try:
      out['number'] = int(q['number'])
    except:
      print("Question number not given")
      sys.exit(1)
    if out['number'] in question_indeces:
      print("Question index: " + str(out['number'] + " repeated"))
      sys.exit(1)
    question_indeces.append(out['number'])

    try:
      out['answer_type'] = q['answer_type'].strip()
    except:
      print("Answer type (single, multi, etc.) not given for question #" + str(out['number']))
      sys.exit(1)

    try:
      out['chapter'] = int(q['chapter'])
    except:
      print("Chapter number not given in question #" + str(out['number']))
      sys.exit(1)

    try:
      out['section'] = int(q['section'])
    except:
      print("Section number not given in question #" + str(out['number']))
      sys.exit(1)

    # count unique sections
    current_section = str(out['chapter']) + "." + str(out['section'])
    if current_section not in used_sections:
      used_sections.append(current_section)
      unique_sections += 1

    try:
      out['difficulty'] = q['difficulty'].strip()
    except:
      print("Difficulty not given in question #" + str(out['number']))
      sys.exit(1)

    # count difficulties
    if out['difficulty'] == "hard":
      difficulty_count[0] += 1
    elif out['difficulty'] == "medium":
      difficulty_count[1] += 1
    elif out['difficulty'] == "easy":
      difficulty_count[2] += 1
    else:
      sys.exit("Unknown difficulty marker")

    try:
      if out['answer_type'].lower() == 'blank_answer':
        prompt = [m.groupdict() for m in blanks_rx.finditer(q['prompt'].strip())]
        out['prompt'] = []
        out['answers'] = None
        out['correct'] = []
        for a in prompt:
          if a['text']:
            out['prompt'].append(a['text'])
          if a['blank']:
            if ANSWERS_DEBUG:
              out['prompt'].append(markBlank(a['blank']))
            out['prompt'].append(len(out['correct']))
            out['correct'].append(a['blank'])
      elif out['answer_type'].lower() == 'single' or out['answer_type'].lower() == 'multiple' or out['answer_type'].lower() == 'sort':
        out['prompt'] = q['prompt'].strip()
        out['answers'] = []
        out['correct'] = []
        try:
          answers = [m.groupdict() for m in answ_rx.finditer(q['answers'].strip()+"\n")]
        except:
          print("Answers not given or malformed for question #" + str(out['number']))
          sys.exit(1)
        for i, a in enumerate(answers):
          out['answers'].append(a['answer'].strip())
          if a['correct'] == "*":
            out['correct'].append(i)
            # if answer debug flag is set append correct answer indicator
            if ANSWERS_DEBUG:
              out['answers'][i] = markAnswerCh(out['answers'][i])
          elif ')' in a['correct']:
            out['correct'].append( int(a['correct'].strip().strip(')').strip())  )
            # if answer debug flag is set append correct ordering
            if ANSWERS_DEBUG:
              out['answers'][i] = markAnswerOr(out['answers'][i], out['correct'][-1])
      elif out['answer_type'].lower() == 'cloze_answer':
        try:
          answers = [m.groupdict() for m in mx_rx.finditer(q['answers'].strip()+"\n")][0]
        except:
          print("Answers not given or malformed (contingency table) for question #" + str(out['number']))
          sys.exit(1)
        out['prompt'] = q['prompt'].strip()
        out['answers'] = None
        # reformat output
        out['correct'] = { 00:answers['oo'], 01:answers['oi'], 02:answers['oz'], 10:answers['io'], 11:answers['ii'], 12:answers['iz'], 20:answers['zo'], 21:answers['zi'], 22:answers['zz'] }
      elif out['answer_type'].lower() == 'matrix_sort_answer':
        out['answers'] = []
        out['correct'] = []
        try:
          answers = [m.groupdict() for m in answ_rx.finditer(q['answers'].strip()+"\n")]
          for an in answers:
            an2p = an['answer'].split('<->')
            if ANSWERS_DEBUG:
              out['answers'].append(an2p[0].strip() + " " + markBlank(an2p[1].strip()))
            else:
              out['answers'].append(an2p[0].strip())
            out['correct'].append(an2p[1].strip())
        except:
          print("Answers not given or malformed (missing *<->* indicator?) for question #" + str(out['number']))
          sys.exit(1)
        out['prompt'] = q['prompt'].strip()
      else:
        print "Unrecognised type of question: " + out['answer_type']
        sys.exit(1)
    except:
      print("Question not given in question #" + str(out['number']))
      sys.exit(1)

    out['captions'] = []
    out['images'] = []
    if q['images']:
      images = [m.groupdict() for m in img_rx.finditer(q['images'].strip())]

      for a in images:
        out['captions'].append(a['caption'].strip())
        out['images'].append(a['path'].strip())

    if q['text']:
      out['text'] = q['text'].strip()
    else:
      out['text'] = '-'

    # full question text
    if q['fullq']:
      out['fullq'] = q['fullq']
    else:
      sys.error("Couldn't parse the whole question!")

    # quality control
    if q['quality']:
      out['quality'] = True
    else:
      out['quality'] = False

    results.append(out)

  return(results, title, url, uid, unique_sections, difficulty_count)

# return HTML image environment
def insertImage(path, caption):
  return "<br><figure><img src=\"" + path + "\" /><figcaption>" + caption + "</figcaption></figure>"

# This function generates the JSON code that is required for the quiz
# library to grade the quizzes
def htmlToJson(question):
  json = {
    "type"   : question["answerType"],
    "id"     : question["id"],
    "catId"  : 0,
    "points" : 1,
    "correct": question["correctness"]
  }
  return json

# prepare and write results to html file
def toHtml(filename, results, title, qToGen):
  # skip all the other questions if only interested in one
  separateFilenames = False
  if type(qToGen) == list:
    for r in results:
      if qToGen[-1] == r['number']:
        resultsU = [r]
        resultPartition = [resultsU]
        break
  elif qToGen == None:
    resultsU = results
    resultPartition = [resultsU]
  elif qToGen:
    separateFilenames = True
    resultPartition = [[r] for r in results]
  else:
    sys.error("I shouldn't be here")

  # memorise question filenames if generating separately
  Qfilenames = []

  for rU in resultPartition:
    questions = []
    jsons = {}
    for result in rU:
      question = {}
      question["questionNumber"] = question["id"] = result['number']
      question["category"]       = str(result['chapter']) + "." + str(result['section']) +\
        ": " +  questionCategories[result['chapter']][0] + " : " +\
        questionCategories[result['chapter']][result['section']]
      question["difficulty"]     = result['difficulty']

      # prepare question to display: text + images
      question["question"]       = result['prompt']
      for i in range(len(result['images'])):
        question["question"] += insertImage(result['images'][i], result['captions'][i])

      if result['answer_type'] == 'single':
        # Loop over the answers and extract the text if it has been filled in appropriately
        # remodel answers so that the first one in the list is correct
        # TODO: fix in the same way as in multiple answers
        rAnswers = result['answers'][:]
        rAnswers_c = rAnswers.pop(result['correct'][0])
        rAnswers.insert(0, rAnswers_c)
        answers = []
        for ai, answer in enumerate(rAnswers):
          answers.append( dict(
            answerPos_0 = ai,
            answerPos_1 = ai + 1,
            id = question["id"],
            answerText = answer) )

        question["answers"] = answers

        question["correctness"] = [0] * len( question["answers"] )
        question["correctness"][0] = 1

        question["answersStr"] = "\n".join( singleTemplate % answer for answer in answers )
        question["numAnswers"] = len( answers )
        question["answerType"] = result['answer_type']
        question["json"] = htmlToJson( question )
        question["questionHTML"] = questionTemplate % question
      elif result['answer_type'] == 'multiple':
        answers = []
        for ai, answer in enumerate(result['answers']):
          answers.append( dict(
            answerPos_0 = ai,
            answerPos_1 = ai + 1,
            id = question["id"],
            answerText = answer) )
        question["answers"] = answers

        question['correctness'] = [0] * len( question["answers"] )
        for ri in result['correct']:
          question["correctness"][ri] = 1

        question["answersStr"] = "\n".join( multipleTemplate% answer for answer in answers )
        question["numAnswers"] = len( answers )
        question["answerType"] = result['answer_type']
        question["json"] = htmlToJson( question )
        question["questionHTML"] = questionTemplate % question
      elif result['answer_type'] == 'sort':
        answers = []
        for ai, answer in enumerate(result['answers']):
          answers.append( dict(
            answerPos_0 = ai,
            answerPos_1 = ai + 1,
            id = question["id"],
            answerText = answer) )
        question["answers"] = answers

        question["correctness"] = result['correct']

        question["answersStr"] = "\n".join( sortTemplate% answer for answer in answers )
        question["numAnswers"] = len( answers )
        question["answerType"] = result['answer_type']
        question["json"] = htmlToJson( question )
        question["questionHTML"] = questionTemplate % question
      elif result['answer_type'] == 'blank_answer':
        # overwrite the question prompt
        question["question"] = "Fill in the blanks"
        question["rawQuestion"] = mergeBlanks(result['prompt'], result['correct'])

        # Build up the dictionary of answers
        question["answers"] = []
        question["correctness"] = []
        for ic in result['correct']:
          ic_r = ic.split(',')
          ic_r = [r.strip() for r in ic_r]
          question["correctness"].append(ic_r)
          question["answers"].append({'length':max(map(len,ic_r)), 'answers':"("+', '.join(ic_r)+")"})

        questionStr = fillBlanks(result['prompt'], question["answers"])

        question["answerType"] = result['answer_type']
        question["numAnswers"] = len( question["answers"] )
        question["json"] = htmlToJson( question )
        question["answersStr"] = str( blankTemplate % questionStr )

        question["questionHTML"] = questionTemplate % question
      elif result['answer_type'] == 'cloze_answer':
        answers = []
        question["correctness"] = []
        # get dictionary keys and order them
        answerKeys = result['correct'].keys()
        answerKeys.sort()
        for ai, answer in enumerate( answerKeys ):
          answerText = str( result['correct'][answer] )
          question["correctness"].append( answerText )
          answers.append( dict( answerPos_0 = ai,
            answerPos_1 = ai + 1,
            id = question["id"],
            answerText = answerText ) )
        # Populate the question dict with the answers provided
        question["answerType"] = result['answer_type']
        question["answers"] = answers
        question["numAnswers"] = len( answers )
        question["json"] = htmlToJson( question )
        # decide on template to fill based on debugging state
        template = None
        if ANSWERS_DEBUG:
          marked = [markBlank(x) for x in question["correctness"]]
          template = [x for pair in zip(marked,question["correctness"]) for x in pair]
        else:
          template = [x for pair in zip(['']*len(question["correctness"]),question["correctness"]) for x in pair]
        question["answersStr"] = tableTemplate % tuple( template )
        question["questionHTML"] = questionTemplate % question
      elif result['answer_type'] == 'matrix_sort_answer':
        answerList = []
        questionList = []
        question["answers"] = []

        for ai, (t0,t1) in enumerate( zip(result['answers'], result['correct']) ):
          question["answers"].append( ( t1, t0 ) )
          answerList.append( matrixSort_answers_single % { "answerPos_0": ai, "answer": t1 } )
          questionList.append( matrixSort_question_single % { "answerPos_0": ai, "answer": t0 } )

        qaSet = { "ms_questions": "".join( quest for quest in answerList ), "ms_questionsSet": questionList, "ms_answers": "".join( quest for quest in questionList ), "ms_answersSet": answerList }
        question = dict( dict( qaSet.items() + question.items() ) )

        # Populate the question dict with the answers provided
        question["answerType"] = result['answer_type']
        question["numQuestions"] = 0
        # answerStr | correctness
        question["correctness"] = range( len( answerList ) )
        question["numAnswers"] = len( answerList )
        question["json"] = htmlToJson( question )
        question["questionHTML"] = matrixSort_questionTemplate % question
      else:
        print( "Question type not recognised: " + result['answer_type'] + " !" )
        sys.exit(1)

      jsons[str( question["id"] )] = question["json"]
      questions.append( question["questionHTML"] )

    quiz = dict( \
      quizTitle = title,
      questions = '\n'.join( questions ),
      answersJSON = jsons )

    if separateFilenames:
      qfile = filename[:-5] + "_Q" + str(rU[-1]['number']) + ".html"
      Qfilenames.append(qfile)
      with open(qfile, 'w') as outfile:
        outfile.write(quizTemplate % quiz)
    else:
      if len(resultPartition) != 1:
        sys.error("Bizarre")
      with open(filename[:-5] + ".html", 'w') as outfile:
        outfile.write(quizTemplate % quiz)

  return Qfilenames

def toJson(filename, results, title, url, uid):
  with open(filename[:-5] + ".json", 'w') as outfile:
    json.dump(
      {
        "questions" : sorted(results, key=lambda x: x['number']),
        "title" : title,
        "url" : url,
        "uid" : uid
      },
      outfile,
      sort_keys=True,
      indent=2,
      separators=(',', ': ')
    )

#
# update filename in index.html
#
def updateIndex(dirname, jsonPath):
  # prepare JSON filename i.e. remove directories just leave filename
  jsonName = None
  jsonName_i = jsonPath[::-1].find('/')
  if jsonName_i == -1:
    jsonName = jsonPath
  else:
    jsonName =jsonPath[::-1][:jsonName_i][::-1]

  with open(dirname + "index.html", 'w') as writer:
    with open(dirname + "resources/index.html", 'r') as reader:
      for line in reader:
        writer.write(line.replace("my_quiz.json", jsonName))

#
# generate feedback for given user
#
def toFeedback( rootDir, uid, results, sectionCoverage, difficulty ):
  d = []
  for r in results:
    d.append('#' + str(r['number']) + ': ' + r['text'])
  d.sort()

  feedbackFile = rootDir + "feedback_" + uid + ".txt"
  with open(feedbackFile, 'w') as ffile:
    ffile.write( quizStats(uid, len(results), sectionCoverage, difficulty) )
    ffile.write( '\n'.join(d) )

#
# generate marked questions
#
def extract(rootDir, uid, results):
  d = [ 'uid: ' + uid + '\n' ]
  for r in results:
    if r['quality']:
      d.append(r['fullq'])

  extractFile = rootDir + "extract_" + uid + ".quiz"
  with open(extractFile, 'w') as efile:
    efile.write( '\n'.join(d) )

#
# generate iFrame
#
def writeIframe(filename, questionFilenames):
  frames = ""
  for f in questionFilenames:
    frames += iframeIframeTemplate % {'filename':f, 'filename':f}
  with open(filename[:-5] + "_iFrame.html", 'w') as if_file:
    if_file.write(iframeGeneralTemplate % {'iframes':frames})

#
# order questions
#
def orderQuestions(filename, order, uid, questions):

  if order == 'O':
    of = '^'
    out = sorted(questions, key=lambda elem: "%s %02d.%02d" % (elem['difficulty'], elem['chapter'], elem['section']))
  elif order == 'o':
    of = 'v'
    out = sorted(questions, key=lambda elem: "%02d.%02d %s" % (elem['chapter'], elem['section'], elem['difficulty']))
  else:
    sys.exit('Unknown order')

  with open(filename[:-5] + "_" + of + order + ".quiz", 'w') as o_file:
    o_file.write( 'uid: '+uid+'\n' )
    for i in out:
      o_file.write( '\n' + i['fullq'] )

  return out

#
# produce quiz statistics#
#
def quizStats(uid, questionCount, sectionCoverage, difficulty):
  stats =("-----------------------------|\n" +\
          "^ hard:             %2d (%2d%%) |\n" +\
          "| medium:           %2d (%2d%%) |\n" +\
          "v easy:             %2d (%2d%%) |\n" +\
          "-----------------------------|\n" +\
          "~ total:            %2d       |\n" +\
          "-----------------------------|\n" +\
          "@ section coverage: %2d       |\n" +\
          "-----------------------------|\n" ) %\
          (difficulty[0], 100.0*difficulty[0]/questionCount, \
          difficulty[1], 100.0*difficulty[1]/questionCount, \
          difficulty[2], 100.0*difficulty[2]/questionCount, \
          questionCount, sectionCoverage)

  difficultyRequirements = "\n"
  uidGroup = uid_rx.match(uid)
  if uidGroup:
    authors = '---'.join(list(uidGroup.groups()))
    authorsNo = 2
    if questionCount < 50: difficultyRequirements += "& too little questions &"
    if sectionCoverage < 25: difficultyRequirements += "& too few sections &"
  else:
    authors = uid
    authorsNo = 1
    if questionCount < 30: difficultyRequirements += "& too little questions &"
    if sectionCoverage < 15: difficultyRequirements += "& too few sections &"

  if 100.0*difficulty[2]/questionCount > 40: difficultyRequirements += "& too many easy &"
  if 100.0*difficulty[0]/questionCount < 20: difficultyRequirements += "& too few hard &"

  detection = ""
  if difficultyRequirements != "\n":
    detection += "Detected " + str(authorsNo)
    if authorsNo == 1:
      detection += " author: "
    else:
      detection += " authors: "
    detection += str(authors) + "\nDifficulty requirements broken:\n  " +\
      difficultyRequirements

  return stats + difficultyRequirements

if __name__ == '__main__':
  # parse arguments
  args = parser.parse_args()
  ANSWERS_DEBUG = args.debug
  quizFilename = args.filename[0]
  # check if given file exists
  if os.path.exists(quizFilename):
    if os.path.isfile(quizFilename):
      if quizFilename[-5:] != ".quiz":
        print("Your file must have `.quiz` extension")
        sys.exit(1)
    else:
      print(quizFilename + " is not a file!")
      sys.exit(1)
  else:
    print(quizFilename + " does not exist!")
    sys.exit(1)
  # check if the file is located in the root of the repository
  rootDir_i = quizFilename[::-1].find('/')
  if rootDir_i != -1:
    rootDir = quizFilename[::-1][rootDir_i:][::-1]
  else:
    rootDir = "./"
  if not os.path.exists(rootDir+"resources/js/wpProQuiz_jquery.ui.touch-punch.min.js"):
    print "Your .quiz files must be located in the root directory of this package to work properly"
    sys.exit(1)

  results, title, url, uid, sectionCoverage, difficulty = parseQuestions(quizFilename)

  # order questions if needed
  if args.order:
    print "Ordering the questions first on book section then on difficulty"
    results = orderQuestions(quizFilename, 'o', uid, results)
  elif args.Order:
    print "Ordering the questions first on difficulty then on book section"
    results = orderQuestions(quizFilename, 'O', uid, results)

  if args.feedback:
    print( "Generating feedback for " + uid )
    toFeedback( rootDir, uid, results, sectionCoverage, difficulty )
  elif args.question:
    print( "Generating question #" + str(args.question[-1]) )
    toHtml(quizFilename, results, title, args.question)
  elif args.extract:
    # extract marked questions
    print( "Extracting marked questions" )
    extract(rootDir, uid, results)
  elif args.iframe:
    print( "Generating all of the questions in one file (iframe)" )
    qfilenames = toHtml(quizFilename, results, title, True)
    # generate iframe with filenames
    writeIframe(quizFilename, qfilenames)
  elif args.separate:
    print( "Generating all of the questions in separate files" )
    toHtml(quizFilename, results, title, args.separate)
  # must be the last element of if-elif-else
  elif args.all:
    print( "Generating all of the questions" )
    toHtml(quizFilename, results, title, None)
  else:
    print( "I didn't expect to get here..." )
    sys.exit(1)

  if args.count:
    print quizStats(uid, len(results), sectionCoverage, difficulty),

    #TODO: argument flag to generate JSON
    # quizJson = quizFilename[:-5] + ".json"
    # print("generating " + quizJson)
    # results, title, url, uid = parseQuestions(quizFilename)
    # toJson(quizFilename, results, title, url, uid)

    # indexFilename = None
    # indexDir_i = quizFilename[::-1].find('/')
    # if indexDir_i != -1:
      # indexDir = quizFilename[::-1][indexDir_i:][::-1]
    # else:
      # indexDir = "./"
    # indexFilename = indexDir + "index.html"
    # print("updating " + indexFilename)
    # updateIndex(indexDir, quizJson)
